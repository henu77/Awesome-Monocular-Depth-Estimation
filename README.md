# Awesome Monocular Depth Estimation

A curated list of monocular depth estimation papers.

The list focuses primarily on papers published after 2022, including some particularly outstanding work from earlier years.

精选单目深度估计论文列表。精选并整理了 `2022` 年后发表的单目深度估计论文，同时涵盖部分早期的优秀成果。

## 2025


 [Depth Pro: Sharp Monocular Metric Depth in Less Than a Second](https://arxiv.org/abs/2410.02073) ![Static Badge](https://img.shields.io/badge/ICLR-FF0000)



Conference/Journal: ICLR

Institution: Apple Inc.

Code: [GitHub](https://github.com/apple/ml-depth-pro)


Abstract: We present a foundation model for zero-shot metric monocular depth estimation. Our model, Depth Pro, synthesizes high-resolution depth maps with unparalleled sharpness and high-frequency details. The predictions are metric, with absolute scale, without relying on the availability of metadata such as camera intrinsics. And the model is fast, producing a 2.25-megapixel depth map in 0.3 seconds on a standard GPU. These characteristics are enabled by a number of technical contributions, including an efficient multi-scale vision transformer for dense prediction, a training protocol that combines real and synthetic datasets to achieve high metric accuracy alongside fine boundary tracing, dedicated evaluation metrics for boundary accuracy in estimated depth maps, and state-of-the-art focal length estimation from a single image. Extensive experiments analyze specific design choices and demonstrate that Depth Pro outperforms prior work along multiple dimensions.


## 2024

## 2023

## 2022

## earlier
